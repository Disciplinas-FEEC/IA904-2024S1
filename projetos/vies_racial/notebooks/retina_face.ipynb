{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from retinaface import RetinaFace\n",
    "import pandas as pd     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo o arquivo do conjunto de dados FairFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/raw/fairface_label_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando cada etnia para um dataframe diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_east_asian=df[df['race']=='East Asian']\n",
    "df_indian=df[df['race']=='Indian']\n",
    "df_black=df[df['race']=='Black']\n",
    "df_white=df[df['race']=='White']\n",
    "df_middle_eastern=df[df['race']=='Middle Eastern']\n",
    "df_latino_hispanic=df[df['race']=='Latino_Hispanic']\n",
    "df_southeast_asian=df[df['race']=='Southeast Asian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi avaliado cada etnia separadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race=df_southeast_asian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criada uma nova coluna no dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race['faces_retina']=pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi aplicado o modelo Retina Face e apresesentado a quantidade de faces que foi possível detectar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for index, row in df_race.iterrows():  \n",
    "    image_path_short = row['file']\n",
    "    image_path_long = '../data/raw/' + image_path_short\n",
    "    try:\n",
    "        resp = RetinaFace.detect_faces(image_path_long)\n",
    "        df_race.loc[index, 'faces_retina'] = len(resp)\n",
    "    except:\n",
    "        df_race.loc[index, 'faces_retina'] = 'não foi detectado nenhum rosto'\n",
    "    if i>2000:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado foi salvo na pasta data/interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race.to_csv('../data/interim/retina_face_southeast_asian.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para avaliação, foram lidos todos os conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_black=pd.read_csv(\"../data/interim/retina_face_black.csv\")\n",
    "df_east_asian=pd.read_csv(\"../data/interim/retina_face_east_asian.csv\")\n",
    "df_indian=pd.read_csv(\"../data/interim/retina_face_indian.csv\")\n",
    "df_latino_hispanic=pd.read_csv(\"../data/interim/retina_face_latino_hispanic.csv\")\n",
    "df_middle_eastern=pd.read_csv(\"../data/interim/retina_face_middle_eastern.csv\")\n",
    "df_southeast_asian=pd.read_csv(\"../data/interim/retina_face_southeast_asian.csv\")\n",
    "df_white=pd.read_csv(\"../data/interim/retina_face_white.csv\")\n",
    "list_dfs=[df_black, df_east_asian, df_indian, df_latino_hispanic, df_middle_eastern, df_southeast_asian, df_white]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi avaliado a quantidade de imagens que o modelo foi aplicado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de valores não vazios no dataframe da raça Black : 2002\n",
      "Quantidade de valores não vazios no dataframe da raça East Asian : 2002\n",
      "Quantidade de valores não vazios no dataframe da raça Indian : 2002\n",
      "Quantidade de valores não vazios no dataframe da raça Latino_Hispanic : 2002\n",
      "Quantidade de valores não vazios no dataframe da raça Middle Eastern : 2002\n",
      "Quantidade de valores não vazios no dataframe da raça Southeast Asian : 2002\n",
      "Quantidade de valores não vazios no dataframe da raça White : 2002\n"
     ]
    }
   ],
   "source": [
    "for df in list_dfs:\n",
    "    print('Quantidade de valores não vazios no dataframe da raça', df['race'][0],':', df['faces_retina'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi avaliado a quantidade de imagens que não foi possível detectar o rosto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe de Erros na Raça  Black :\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, file, age, gender, race, service_test, faces_retina]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Dataframe de Erros na Raça  East Asian :\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, file, age, gender, race, service_test, faces_retina]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Dataframe de Erros na Raça  Indian :\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, file, age, gender, race, service_test, faces_retina]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Dataframe de Erros na Raça  Latino_Hispanic :\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, file, age, gender, race, service_test, faces_retina]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Dataframe de Erros na Raça  Middle Eastern :\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, file, age, gender, race, service_test, faces_retina]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Dataframe de Erros na Raça  Southeast Asian :\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, file, age, gender, race, service_test, faces_retina]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Dataframe de Erros na Raça  White :\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, file, age, gender, race, service_test, faces_retina]\n",
      "Index: []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in list_dfs:\n",
    "    print('Dataframe de Erros na Raça ', df['race'][0], ':')\n",
    "    print(df[df['faces_retina']==0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi instalado a biblioteca fairlearn para avaliar o viés no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairlearn\n",
      "  Downloading fairlearn-0.10.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fairlearn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fairlearn) (2.2.2)\n",
      "Collecting scikit-learn>=1.2.1 (from fairlearn)\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.9.3 (from fairlearn)\n",
      "  Downloading scipy-1.14.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 60.8/60.8 kB 814.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.2.1->fairlearn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.2.1->fairlearn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
      "Downloading fairlearn-0.10.0-py3-none-any.whl (234 kB)\n",
      "   ---------------------------------------- 0.0/234.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 234.1/234.1 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.0-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.0 MB 30.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.2/11.0 MB 27.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 25.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.7/11.0 MB 26.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 21.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.0 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 23.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 23.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.6/11.0 MB 24.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 22.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 16.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.0-cp311-cp311-win_amd64.whl (44.7 MB)\n",
      "   ---------------------------------------- 0.0/44.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.1/44.7 MB 23.3 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 2.1/44.7 MB 26.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.4/44.7 MB 27.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.7/44.7 MB 26.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 4.8/44.7 MB 23.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 6.2/44.7 MB 23.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 7.4/44.7 MB 23.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.6/44.7 MB 24.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.3/44.7 MB 25.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.3/44.7 MB 25.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 12.2/44.7 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.6/44.7 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.1/44.7 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.3/44.7 MB 25.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.6/44.7 MB 23.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.5/44.7 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.5/44.7 MB 25.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.2/44.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 20.7/44.7 MB 22.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.7/44.7 MB 27.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 23.9/44.7 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 25.2/44.7 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 26.5/44.7 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 27.4/44.7 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 28.7/44.7 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.8/44.7 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 31.0/44.7 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 32.1/44.7 MB 27.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.9/44.7 MB 25.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.4/44.7 MB 26.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.4/44.7 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 36.7/44.7 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.8/44.7 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.8/44.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.8/44.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.1/44.7 MB 24.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.6/44.7 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.3/44.7 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.7 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.7/44.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.7/44.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.7/44.7 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.7/44.7 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 301.8/301.8 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, fairlearn\n",
      "Successfully installed fairlearn-0.10.0 joblib-1.4.2 scikit-learn-1.5.0 scipy-1.14.0 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: C:\\Users\\DELL\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fairlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas os diferentes dataframes foram unidos novamente em um só"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(list_dfs)\n",
    "\n",
    "# Sort the combined DataFrame by the index column\n",
    "df_retina = combined_df.sort_values(by='Unnamed: 0')\n",
    "\n",
    "# Reset the index if you want a clean integer index\n",
    "df_retina.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_retina.head()\n",
    "\n",
    "df_retina['face_detected'] = df_retina['faces_retina'] >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O seguinte código calcula as métricas para avaliação de viés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15704\\3884262700.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['face_present'] = df['service_test']  # Supondo que 'service_test' é True se um rosto está presente\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame, true_positive_rate, true_negative_rate, false_positive_rate, false_negative_rate, selection_rate\n",
    "\n",
    "df=df_retina\n",
    "\n",
    "# Verificar se a coluna 'service_test' representa a verdade sobre a presença de um rosto\n",
    "df['face_present'] = df['service_test']  # Supondo que 'service_test' é True se um rosto está presente\n",
    "# Definir as colunas para avaliação\n",
    "y_true = df['face_present']\n",
    "y_pred = df['face_detected']\n",
    "sensitive_features = df[['gender', 'race']]\n",
    "\n",
    "\n",
    "# Calcular métricas usando Fairlearn\n",
    "metrics = {\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'false_positive_rate': false_positive_rate,\n",
    "    'true_negative_rate': true_negative_rate,\n",
    "    'false_negative_rate': false_negative_rate,\n",
    "    'selection_rate': selection_rate\n",
    "}\n",
    "\n",
    "metric_frame = MetricFrame(metrics=metrics, y_true=y_true, y_pred=y_pred, sensitive_features=sensitive_features)\n",
    "\n",
    "# Paridade Demográfica: selection_rate\n",
    "demographic_parity = metric_frame.by_group['selection_rate']\n",
    "print(\"\\nParidade Demográfica (Taxa de Seleção por Raça):\")\n",
    "print(demographic_parity)\n",
    "\n",
    "# Igualdade de Oportunidade: true_positive_rate\n",
    "equalized_opportunity = metric_frame.by_group['true_positive_rate']\n",
    "print(\"\\nIgualdade de Oportunidade (Taxa de Verdadeiros Positivos por Raça):\")\n",
    "print(equalized_opportunity)\n",
    "\n",
    "# Igualdade de Chance: true_positive_rate e false_negative_rate\n",
    "equalized_chance = metric_frame.by_group[['true_positive_rate', 'false_positive_rate']]\n",
    "print(\"\\nIgualdade de Chance (Taxas de Verdadeiros Positivos e Falsos Negativos por Raça):\")\n",
    "print(equalized_chance)\n",
    "\n",
    "# Compute true positive rate and false positive rate by group\n",
    "true_positive_rates = metric_frame.by_group['true_positive_rate']\n",
    "false_positive_rates = metric_frame.by_group['false_positive_rate']\n",
    "\n",
    "# Compare true positive rate and false positive rate for each group\n",
    "predictive_parity = (true_positive_rates - false_positive_rates).abs()\n",
    "\n",
    "print(\"Predictive Parity (Absolute Difference between True Positive Rate and False Positive Rate by Race):\")\n",
    "print(predictive_parity)\n",
    "\n",
    "# Compute false positive rate and false negative rate by group\n",
    "false_positive_rates = metric_frame.by_group['false_positive_rate']\n",
    "false_negative_rates = metric_frame.by_group['false_negative_rate']\n",
    "\n",
    "# Compare false positive rate and false negative rate for each group\n",
    "treatment_equality = (false_positive_rates - false_negative_rates).abs()\n",
    "\n",
    "print(\"Equality of Treatment (Absolute Difference between False Positive Rate and False Negative Rate by Race):\")\n",
    "print(treatment_equality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blaze_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
